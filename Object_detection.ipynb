{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cPY9Ou4sWs_"
   },
   "outputs": [],
   "source": [
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "import time\n",
    "\n",
    "# Print Tensorflow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGkrXGy62409"
   },
   "source": [
    "## Example use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlA3CftFpRiW"
   },
   "source": [
    "### Helper functions for downloading images and for visualization.\n",
    "\n",
    "Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9IwDpOtpIHW"
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "    #plt.savefig(\"test.png\")\n",
    "    #cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "\n",
    "\n",
    "# def download_and_resize_image(url, new_width=256, new_height=256,\n",
    "#                               display=False):\n",
    "#     _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "#     response = urlopen(url)\n",
    "#     image_data = response.read()\n",
    "#     image_data = BytesIO(image_data)\n",
    "#     pil_image = Image.open(image_data)\n",
    "#     pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "#     pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "#     pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "#     print(\"Image downloaded to %s.\" % filename)\n",
    "#     if display:\n",
    "#     display_image(pil_image)\n",
    "#     return filename\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,  ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "    \n",
    "   # print(left, right, top , bottom)\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)],\n",
    "                       fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "                  display_str,\n",
    "                  fill=\"black\",\n",
    "                  font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "# def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "#     \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "#     colors = list(ImageColor.colormap.values())\n",
    "\n",
    "#     try:\n",
    "#         font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "#                               25)\n",
    "#     except IOError:\n",
    "#         print(\"Font not found, using default font.\")\n",
    "#         font = ImageFont.load_default()\n",
    "\n",
    "#     for i in range(min(boxes.shape[0], max_boxes)):\n",
    "#         if scores[i] >= min_score:\n",
    "#             ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "#             display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "#                                          int(100 * scores[i]))\n",
    "#             color = colors[hash(class_names[i]) % len(colors)]\n",
    "#             image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "#             draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color, font, display_str_list=[display_str])\n",
    "#             np.copyto(image, np.array(image_pil))\n",
    "#     return image\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.3):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(len(boxes), max_boxes)):\n",
    "        #if scores[i] >= min_score:\n",
    "        ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "        display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "        color = colors[hash(class_names[i]) % len(colors)]\n",
    "        image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "        draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color, font, display_str_list=[display_str])\n",
    "        np.copyto(image, np.array(image_pil))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D19UCu9Q2-_8"
   },
   "source": [
    "## Apply module\n",
    "\n",
    "Load a public image from Open Images v4, save locally, and display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-VdfLbC1w51"
   },
   "source": [
    "Pick an object detection module and apply on the downloaded image. Modules:\n",
    "* **FasterRCNN+InceptionResNet V2**: high accuracy,\n",
    "* **ssd+mobilenet V2**: small and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uazJ5ASc2_QE"
   },
   "outputs": [],
   "source": [
    "module_handle = \"C:\\\\Users\\\\soena\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
    "\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znW8Fq1EC0x7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwGJV96WWBLH"
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "def run_detector(detector, path):\n",
    "    img = load_img(path)\n",
    "\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    #print(result)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "    \n",
    "    #print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "    print(\"Inference time: \", end_time-start_time)\n",
    "        \n",
    "    boxes = []\n",
    "    scores=[]\n",
    "    entities = []\n",
    "    for i in range(len(result[\"detection_boxes\"])):\n",
    "\n",
    "        if (result[\"detection_scores\"][i]<0.2):\n",
    "            break\n",
    "        ymin, xmin, ymax, xmax = tuple(result[\"detection_boxes\"][i])\n",
    "        flag = 0\n",
    "        for item in boxes:\n",
    "            y1,x1,y2,x2 = tuple(item)\n",
    "            total_diff = abs(ymin-y1)+abs(xmin-x1)+abs(ymax-y2)+abs(xmax -x2)\n",
    "            if(total_diff < 0.1):\n",
    "                flag=1\n",
    "                break\n",
    "        if(result[\"detection_class_entities\"][i].decode(\"ascii\") in ['Truck', 'Bus', 'Land vehicle' ,'Vehicle'] and i!=0):\n",
    "            flag=1\n",
    "        if(flag==0 or i==0):\n",
    "            boxes.append(list(result[\"detection_boxes\"][i]))\n",
    "            scores.append(result[\"detection_scores\"][i])\n",
    "            entities.append(result[\"detection_class_entities\"][i])\n",
    "        \n",
    "    image_with_boxes = draw_boxes(img.numpy(), boxes, entities, scores)\n",
    "    for i in range(len(entities)):\n",
    "        print(str(entities[i].decode(\"ascii\")) + \" ------ \"+ str(int(scores[i]*100))+\"%\")\n",
    "    green =[2]\n",
    "    pink = [4,5,6]\n",
    "    \n",
    "    if(entities[0]==b'Truck' or entities[0]==b'Bus'):\n",
    "        if(entities.count(b'Wheel')+entities.count(b'Tire') in green):\n",
    "            print(\"FASTag Category - Green (2 Axle Trucks and Buses)\")\n",
    "        elif(entities.count(b'Wheel')+entities.count(b'Tire') == 3):\n",
    "            print(\"FASTag Category - Yellow (3 Axle Trucks and Buses)\")\n",
    "        elif(entities.count(b'Wheel')+entities.count(b'Tire') in pink):\n",
    "            print(\"FASTag Category - Pink (4, 5 or 6  Axle Trucks and Buses)\")\n",
    "        elif(entities.count(b'Wheel')+entities.count(b'Tire') > 6):\n",
    "            print(\"FASTag Category - Sky Blue (7+  Axle Trucks and Buses)\")\n",
    "        else:\n",
    "            print(\"FASTag Category - Green (2 or 3 Axle Trucks and Buses)\")\n",
    "    elif(entities[0]==b'Van'):\n",
    "        print(\"FASTag Category - Orange (Light Commercial Vehicles)\")\n",
    "    elif(entities[0]==b'Car' or entities[0]==b'Jeep' or entities[0]==b'Taxi'):\n",
    "        print(\"FASTag Category - Violet (Car, Jeep, Van, Taxi)\")\n",
    "    elif(entities[0]==b'Land vehicle'):\n",
    "        print(\"FASTag Category - Black (Bulldozer and Earth-movers)\")\n",
    "    else:\n",
    "        print(\"Unable to detect FASTag Category!\")\n",
    "    display_image(image_with_boxes)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_detector(detector, './data/4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, xmin, ymax, xmax = tuple(result[\"detection_boxes\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector1(detector, img):\n",
    "    img = load_img(img)\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "    print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "    image_with_boxes = draw_boxes(\n",
    "      img.numpy(), result[\"detection_boxes\"],\n",
    "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "    display_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vchaUW1XDodD"
   },
   "outputs": [],
   "source": [
    "run_detector(detector, downloaded_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_detector1(detector, r\"C:\\Users\\soena\\videoplayback (1).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUUY3nfRX7VF"
   },
   "source": [
    "### More images\n",
    "Perform inference on some additional images with time tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rubdr2JXfsa1"
   },
   "outputs": [],
   "source": [
    "image_urls = [\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg\",\n",
    "  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\",\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
    "  \"https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg\",\n",
    "  ]\n",
    "\n",
    "def detect_img(image_url):\n",
    "  start_time = time.time()\n",
    "  #image_path = download_and_resize_image(image_url, 640, 480)\n",
    "  run_detector(detector, image_url)\n",
    "  end_time = time.time()\n",
    "  print(\"Inference time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otPnrxMKIrj5"
   },
   "outputs": [],
   "source": [
    "detect_img(r\"C:\\Users\\soena\\dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5F7DkD5NtOx"
   },
   "outputs": [],
   "source": [
    "detect_img(image_urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZ18R7dWNyoU"
   },
   "outputs": [],
   "source": [
    "detect_img(image_urls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(r\"C:\\Users\\soena\\test.mp4\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentframe = 0\n",
    "while(True):\n",
    "      \n",
    "    # reading from frame\n",
    "    ret,frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        name = './data/frame' + str(currentframe) + '.jpg'\n",
    "        print ('Creating...' + name)\n",
    "  \n",
    "        # writing the extracted images\n",
    "        cv2.imwrite(name, frame)\n",
    "  \n",
    "        # increasing counter so that it will\n",
    "        # show how many frames are created\n",
    "        currentframe += 1\n",
    "        #run_detector1(detector, name)\n",
    "        # if video is still left continue creating images\n",
    "        # writing the extracted images\n",
    "          \n",
    "        # increasing counter so that it will\n",
    "        # show how many frames are created\n",
    "\n",
    "    else:\n",
    "        break\n",
    "  \n",
    "# Release all space and windows once done\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_detector(detector, './data/7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
